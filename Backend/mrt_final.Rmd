---
title: "MRT Stations Masterlist"
author: "Choo Choo Train"
date: "`r Sys.Date()`"
output: github_documents
---

```{r setup, include=FALSE}

# Load required packages
library(tidyverse)   # Contains dplyr (data manipulation), tidyr (data tidying), tibble (data frame manipulation)
                     # ggplot2 (data visualisation), purrr (functional programming)
library(rvest)       # For HTML and XML web scraping
library(stringr)     # For string manipulation
library(jsonlite)    # For reading JSON data
library(geosphere)   # For Haversine distance
```

# COMPLETE MRT LIST
The following website from Property Review contains the 251 MRT and LRT station names and codes in Singapore. The 251 contains existing stations along with stations and MRT lines that are under construction, such as the upcoming TEL extensions, the Cross Island Line and the Jurong Regional Line, however some of the stations were missing so we had to check and add stations that were missing in the website

Our project is focused on scoring existing MRT stations based on their vulnerability to breakdowns and delays. After filtering and cleaning our dataset, we are left with 143 unique MRT stations. The `stations` dataframe itself contains 171 rows of data as it counts interchange stations as a separate observation with a different line and station code. There are 25 unique interchange stations, 3 of which (Dhoby Ghaut, Marina Bay, Outram Park) service 3 different MRT lines. The remaining 22 stations service 2 lines. 

## Property Review link
```{r}
mrtstaionlink <- "https://propertyreviewsg.com/complete-singapore-mrt-list-english-and-chinese-station-names/"
page <- read_html(mrtstaionlink)
```

### MRT station names and codes cleaning
The station code, station name and line name has been directly extracted from the Property Review website. These variables have been renamed to `station_code`, `stations` and `line`. 

Additional variables that have been added to the data include:
- `line_code`: which can be extracted from the first two alpha characters in `station_code` and adding an "L" (standing for "Line") at the end
- `line_number`: which can be extracted from the numeric digits in `station_code`, and describes the position of the station along the line (at the front, middle or end)
- `join_station`: a standardised `station_name` variable that can be used to join with other datasets
- `is_interchange`: An indicator variable with values 0 (not an interchange) and 1 (is an interchange), which is obtained by counting the number of occurrences of a station.

```{r}
names <- page %>% html_nodes("table") %>% .[[1]] %>% html_table %>%
  
  select(
    station_code = `Station Code`,
    stations = `MRT Station English Name`,
    line = `MRT Line English`) %>%
  
  # standardise string format
  mutate(line = gsub("-", " ", line)) %>%
  
  # add additional entries for stations with unconventional naming methods
  rbind(c("EW27",	"Boon Lay", "East West Line"),
        c("NE17", "Punggol", "North East Line"),
        c("EW1", "Pasir Ris",	"East West Line"),
        c("NE18", "Punggol Coast", "North East Line"),
        c("DT4", "Hume", "Downtown Line"),
        c("NS12", "Canberra", "North South Line"))%>%
  
  # filter for irrelevant entries
  filter(!str_detect(line, "LRT")) %>%  # remove rows where line contains "LRT" 
  filter(!str_detect(line, "Jurong Region Line")) %>%  # remove "Jurong Region Line" (Not yet built: commencement in 2027-2029)
  filter(!str_detect(line, "Cross Island Line")) %>% # remove "Cross Island Line" (Not yet built: commencement in 2030-2032)
  filter(!(stations %in% c("Mount Pleasant", "Marina South", "Founders' Memorial", "Bedok South", "Sungei Bedok"))) %>% ## underconstruction
  
  drop_na() %>%
  
  mutate(
    line_code = str_extract(station_code, "[A-Za-z]+") %>% paste0("L"),  # Extract line_code using station_code
    line_code = case_when(line_code == "CEL" ~ "CCL",                    # treat Circle Extension as Circle Line
                          TRUE ~ line_code),
    line = case_when(line == "Circle Line Extension" ~ "Circle Line",    # treat Circle Extension as Circle Line
                          TRUE ~ line),
    line_number = as.numeric(str_extract(station_code, "\\d+")),         # Extract line_number
    join_station = tolower(gsub(" ", "", stations))) %>%
  
  # each row is a unique mrt_code, so if station name appears more than once it is an interchange  
  group_by(join_station) %>%
  mutate(is_interchange = ifelse(n() > 1, 1, 0)) %>%
  ungroup() %>%
  arrange(line_code, line_number) 

```

We want to find indicate if the stations are underground or above ground, from our research we found that most lines except for NSL and EWL are built under ground. 
Sources: 

NSL: https://en.wikipedia.org/wiki/North%E2%80%93South_MRT_line 
EWL: https://en.wikipedia.org/wiki/East%E2%80%93West_MRT_line 

EWL is mostly above ground, except for [EW11] Lavender to [EW17] Tiong Bharu.
NSL is mostly above ground, except for [NS18] Braddell to [NS28] Marina South Pier.
Total: 43 stations above ground.

We have indicated the filled the column `is_above_ground` as such:
1: above ground, 0: under ground

```{r}
names <- names %>%
  mutate(
    is_above_ground = case_when(
      line_code =="NSL" & !between(line_number, 19, 27) ~ 1,  # If NS line & line number between 18-28, set to 1
      line_code =="EWL" & !between(line_number, 12, 16) ~ 1,  # If EW line & line number between 11-17, set to 1
      TRUE ~ 0))  # Otherwise, set to 0 (underground)
```

## Wikipedia MRT Line Characteristics
Next, our team found additional information on station and line characteristics from Wikipedia. The variables extracted from the web scrape as follows:
- `operator`: A character variable recording the MRT line's operator; SMRT Trains or SBS Transit
- `commencement`: The start date of operation for the MRT line.
- `line_age`: A numeric variable calculated as a difference between today's date and the commencement date. 
- `n_stations`: The number of stations along an MRT line.
- `length`: The length (in kilometers) of the MRT line.
- `cost`: The total cost of construction for the MRT line.
- `cost_per_km`: The cost of construction per kilometer.

```{r}
wiki_link = "https://en.wikipedia.org/wiki/Mass_Rapid_Transit_(Singapore)"
wiki_page = read_html(wiki_link)
```

```{r}
line_info <- wiki_page %>% html_nodes("table") %>% .[3] %>% html_table() %>% .[[1]] %>%
  
  filter(`Name and colour` != "Total:") %>% 
  
  rename(line = `Name and colour`,
         operator = Operator) %>%
  
  mutate(line = gsub("â€“", " ", line)) %>%    # standardise string format (remove dashes)
  
  mutate(line = case_when(
    `Commencement` == "7 November 1987" ~ "North South Line",  # fix a minor data entry error for North South Line in `line` column
    TRUE ~ line)) %>%                                          # Keep original value otherwise
  
  drop_na() %>%
  
  mutate(line_code = case_when(
           line == "North South Line" ~ "NSL",
           line == "East West Line" ~ "EWL",
           line == "Circle Line" ~ "CCL",
           line == "Downtown Line" ~ "DTL",
           line == "Thomson East Coast Line" ~ "TEL",
           line == "North East Line" ~ "NEL"),
         
         commencement = as.Date(Commencement, format="%d %B %Y"), 
         # line age with reference to commencement date
         line_age = as.numeric(difftime(Sys.Date(), commencement, units = "days")) %/% 365.25) %>%
  
  mutate(
    n_stations = as.numeric(str_remove_all(Stations, "\\[.*?\\]")),         # remove square brackets
    length = str_remove_all(Length, "\\[.*?\\]|\\(.*?\\)"),                 # remove square brackets and parentheses
    length = as.numeric(str_extract(length, "\\d+(\\.\\d+)?")),
    cost = str_remove_all(Cost, "\\[.*?\\]"),
    cost = as.numeric(str_extract(cost, "\\d+(\\.\\d+)?")),                 # in Billions
    ) %>%
  # remove irrelevant columns
  select(-`Previous extension`, -`Next extension`, -Terminus, -`Control Centre`, -Stations, -Length, -Cost, -Commencement, -`Depot(s)`)

```

As the Wikipedia page does not contain information on the Changi Airport Branch Line, we have manually added their information.

```{r}
stations <- names %>% left_join(line_info) %>%
  mutate(                               # handle missing entries for CGL: Changi Airport and Expo stations
  operator = case_when(
    line_code == "CGL" ~ "SMRT Trains",
    TRUE ~ operator),
  commencement = case_when(
    line_code == "CGL" ~ ymd("2002-02-08"),
    TRUE ~ commencement),
  line_age = case_when(
    line_code == "CGL" ~ as.numeric(difftime(Sys.Date(), commencement, units = "days")) %/% 365.25,
    TRUE ~ line_age),
  n_stations = case_when(
    line_code == "CGL" ~ 2,
    TRUE ~ n_stations),
  length = case_when(
    station_code == "CG1" ~ 57.2, # use EWL
    station_code == "CG2" ~ 57.2, # use EWL
    TRUE ~ length),
  cost = case_when(
    station_code == "CG1" ~ 13.68, # use EWL
    station_code == "CG2" ~ 13.68, # use EWL
    TRUE ~ cost)) %>%
  select(-line_age) %>%
  mutate(cost_per_km = cost/length)
```


Save the final MRT Stations masterlist dataset, frontend need to reference
```{r}

stations <- stations %>% group_by(stations) %>% mutate(n_lines = n())
#write.csv(stations, file = "stations.csv")
```



## Ridership Data
Our team collected data on ridership volume to observe any correlation between service disruptions and higher passenger volume. Higher ridership volume leads to more stress on transport infrastructure as train interval timings are usually modified (shortened) to accommodate more passengers. Our data was sourced from ..., and it contains information on .... The variables extracted from the dataset as follows:
- `is_peak`: An indicator variable based on Singapore's weekday peak hour definition; peak is between 6.00am-9.00am and 4.00pm-8.00pm (not inclusive), and these are indicated with 1. Off-peak timings are indicated with 0.
- `day_type`: A factor variable with 2 levels; WEEKDAY and WEEKEND/HOLIDAY.
- `n_riders`: The ridership volume (number of riders)

```{r}
ridership_path_20232024 = "raw_data/transport_node_train_20232024collated.csv"
df2024_2023 <- read.csv(ridership_path_20232024)

# Aggregate average number of riders for weekday and weekend
df_avg_riders <- df2024_2023 %>%
  group_by(TIME_PER_HOUR, DAY_TYPE) %>%
  summarise(AVG_RIDERS = mean(TOTAL_TAP_IN_VOLUME + TOTAL_TAP_OUT_VOLUME, na.rm = TRUE)) %>%
  ungroup()

# Aggregate average number of riders for weekday and weekend
df_avg_riders_clean <- df2024_2023 %>%
  group_by(YEAR_MONTH,TIME_PER_HOUR, DAY_TYPE, PT_CODE) %>%
  summarise(n_riders = round(mean(TOTAL_TAP_IN_VOLUME + TOTAL_TAP_OUT_VOLUME, na.rm = TRUE))) %>%
  ungroup() %>% 
  mutate(is_peak = case_when(TIME_PER_HOUR > 6 & TIME_PER_HOUR < 9 & DAY_TYPE == "WEEKDAY" ~ 1,
                             TIME_PER_HOUR > 16 & TIME_PER_HOUR < 20 & DAY_TYPE == "WEEKDAY" ~ 1,  
                             TRUE ~ 0),
         PT_CODE = sub("/.*", "", PT_CODE),
         month = month(ym(YEAR_MONTH))) %>%
  # since we don't have values for each line in interchange stations we will just drop values behind / for ease of join
  rename("station_code" = "PT_CODE", "hour" = "TIME_PER_HOUR", "day_type" = "DAY_TYPE")

```
### Visualisation
The following graph shows the ridership volume during Weekdays and Weekend / Public holidays.

The plot is bimodal for Weekdays, with two peaks at 8am and 6pm, indicating the height of the morning and evening peaks respectively. These are the hours high stress on MRT systems. 

For Weekdays / Public Holidays, the graph is generally uniform. Passenger volume steadily increases throughout the day from 5am, reaching its highest volume at 5pm and 6pm, which coincide with the dinner crowd. 

No data points are recorded between 1am to 4am as the MRT is closed for operation during those hours. 
```{r}
ggplot(df_avg_riders, aes(x = TIME_PER_HOUR, y = AVG_RIDERS, color = DAY_TYPE)) +
  geom_line(size = 1.2) +  # Line plot
  geom_point(size = 2) +   # Add points for clarity
  labs(title = "Average Number of Riders by Hour (Weekday vs Weekend)",
       x = "Hour of the Day",
       y = "Average Number of Riders",
       color = "Day Type") +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 23, by = 1)) +  # Show all hours
  scale_color_manual(values = c("WEEKDAY" = "blue", "WEEKENDS/HOLIDAY" = "red")) 
```


Since we only have data spanning across Dec-Feb 2024 and 2023 respectively (due to data limitations provided by LTA datamall) + it does not consider the new mrt stations that have recently opened we only can make estimations on the ridership based on the attributes: mrt station, is_peak, DAY_type (weekday or weekend/holiday).
For Hume, since we do not have ridership data, we will take the average of its surrounding stations Hillview MRT Station (DT3) and Beauty World MRT Station (DT5) to make an estimation based on is_peak and DAY_TYPE column.



```{r}
stations_ridership_data <- df2024_2023 %>% 
  mutate(is_peak = case_when(TIME_PER_HOUR > 6 & TIME_PER_HOUR < 9 ~ 1,
                             TIME_PER_HOUR > 16 & TIME_PER_HOUR < 20 ~ 1,  
                             TRUE ~ 0),
         PT_CODE = sub("/.*", "", PT_CODE)
  ) %>%
  mutate(PT_CODE = case_when(
    PT_CODE == 'BP6' ~ 'DT1',
    TRUE ~ PT_CODE  
  ))%>%
  group_by(DAY_TYPE, PT_CODE, is_peak) %>%
  summarise(AVG_RIDERS = mean(TOTAL_TAP_IN_VOLUME + TOTAL_TAP_OUT_VOLUME, na.rm = TRUE)) %>%
  ungroup() %>% 
  left_join(stations, by = c("PT_CODE" = "station_code")) %>%
  filter(!is.na(line_code)) %>%
  select(line_code,DAY_TYPE, PT_CODE, is_peak, stations, AVG_RIDERS)


# Create all combinations of is_peak and DAY_TYPE
peak_day_combos <- expand_grid(
  is_peak = c(0, 1),
  DAY_TYPE = c("WEEKDAY", "WEEKENDS/HOLIDAY")
)


#interchange stations we have to deal with because of the way the data is collected
stations_left_out <- stations %>%
  filter(!station_code %in% unique(stations_ridership_data$PT_CODE)) %>%
  filter(!stations == 'Hume') %>%
  select(station_code,stations,line_code) %>%
  mutate(AVG_RIDERS = 0
         ,PT_CODE = station_code) %>%
  crossing(peak_day_combos) %>%
  select(-station_code)


# getting hume ridership by taking the average amongst the DAY_TYPE, is_peak
hume_ridership <- stations_ridership_data %>%
    filter(PT_CODE %in% c('DT3', 'DT5')) %>%
  group_by(line_code,DAY_TYPE, is_peak) %>%
  summarise(AVG_RIDERS = mean(AVG_RIDERS)) %>%
  ungroup() %>%
  mutate(PT_CODE = 'DT4'
         ,stations = 'Hume')


stations_ridership_data_all <- bind_rows(stations_ridership_data, stations_left_out, hume_ridership)


# The data provided to us was based on the granularity: hour, day, and mrt stations for 6 months, however since we only have 6 months worth of data we will take the average based on the daytype, is_peak and mrt_stations that would provide us with a good estimate of the ridership for each station based on the daytype, is_peak and mrt_stations

avg_by_station_name <- stations_ridership_data_all %>%
  group_by(DAY_TYPE, is_peak, stations) %>%
  summarise(avg_riders_all_lines = mean(AVG_RIDERS, na.rm = TRUE))


# we have to consider because of the way the data is collected, where we are only able to gauge ridership based on the number of tap ins + tap outs ewe have to divide ridership amongst the different stations for interchanges. e.g: NS24 WEEKENDS/HOLIDAY 1 Dhoby Ghaut :32900.77/3 = 10966.922 
stations_final <- stations_ridership_data_all %>%
  left_join(avg_by_station_name, by = c("DAY_TYPE", "is_peak", "stations")) %>%
  mutate(
    AVG_RIDERS = if_else(
      stations %in% unique(stations_left_out$stations),  # basically if there are 3 lines in a station e.g dhouby it will divide according to the different attributes: is_peak, DAY_TYP
      avg_riders_all_lines,
      AVG_RIDERS
    )) %>%
  select(-avg_riders_all_lines) %>%
  rename(station_code = PT_CODE)


```

saving excel for front end
```{r}

#write.csv(stations_final, "ridership_by_stations.csv", row.names = FALSE)


```


Join the `stations` MRT Stations masterlist with the ridership data.
```{r}
stations_ridership <- stations %>%
  left_join(stations_final, by = "station_code") 

```





## Rainfall Data
Our team observed that MRT service disruptions are more frequent during periods of bad weather. As such, we decided to collect data on Singapore's rainfall patterns to observe if weather conditions could help us predict potential service disruptions, and see if certain MRT stations are more prone to breakdowns due to bad weather. 

Our data was obtained using Data.gov, unfortunately our data does not contain the rain collection data for each MRT station but rather coordinates for weather stations that are situated around singapore.
In order to get the rainfall for each mrt station, we would need to get MRT coordinates from OneMap API and get the closest harvesine distanced to the weather station. The code to get this data was done in python, in another file.
.... 

```{r}
data3 <- fromJSON("raw_data/station_data.json")
station_data <- data3$data[[1]] %>% unnest(location)
```

```{r}
mrt_station_coordinates <- read.csv("raw_data/mrt_stations.csv")


mrt_data <- mrt_station_coordinates %>%
  
  # Extract MRT or LRT station names
  mutate(Station_Name = tolower(str_remove_all(building, " MRT STATION| \\(.*\\)"))) %>% 
  
  group_by(Station_Name) %>%
  
  summarise(
    # there are instances whereby different mrt stations have different coordinates so we take the central coordinate for simplicity
    longitude = mean(longitude, na.rm = TRUE), 
    latitude = mean(latitude, na.rm = TRUE)) %>%
    select(Station_Name, longitude, latitude) %>%
    filter(Station_Name %in% tolower(stations$stations))

```

```{r}
write.csv(mrt_data, file = "mrt_coordinates.csv")
```

```{r}

# Define a function to find the closest device for a given MRT station
find_closest_device <- function(mrt_longitude, mrt_latitude, station_data) {
  distance <- Inf
  closest_device_id <- NA
  
  # Loop through each device and compute the distance
  for (station in station_data$id) {
    current_device_data <- station_data[station_data$id == station, ]
    station_longitude <- current_device_data$longitude
    station_latitude <- current_device_data$latitude
    mrt_point <- c(mrt_longitude, mrt_latitude)
    weather_station_point <- c(station_longitude, station_latitude)
    new_distance <- distHaversine(mrt_point, weather_station_point)
    
    # Update the closest device if a smaller distance is found
    if (new_distance < distance) {
      distance <- new_distance
      closest_device_id <- station  # Store just the device ID
    }
  }
  
  return(closest_device_id)  # Return only the ID of the closest device
}

mrt_data <- mrt_data %>%
  rowwise() %>%
  mutate(closest_device = find_closest_device(longitude, latitude, station_data)) %>%
  ungroup() %>%
  select(Station_Name, closest_device) %>%
  mutate(
    Station_Name = gsub(" MRT STATION", "", Station_Name),
    Station_Name = gsub(" ", "", Station_Name)
  ) 
distinct_mrt <- stations %>%
  select(join_station, stations) %>%
  distinct()
allocated_mrt_station <- left_join(distinct_mrt, mrt_data, by = c("join_station" = "Station_Name")) %>% 
  select(stations, join_station, closest_device)

```
breakdown dates needed for api pull to minimise pull time
```{r}
#write.csv(unique(station_breakdown$date), file = "breakdown_date.csv")
```

Allocation of weather stations to each mrt station
```{r}
data <- fromJSON("raw_data/rainfall_data.json") # using only 3 days because the data is too big for github

rain_falldf <- data[2][1] %>% 
  unnest(cols = c(data)) %>% 
  unnest(cols = c(data))%>%
  mutate(
    date = date(timestamp),
  ) %>%
  group_by(date, stationId) %>%
  summarise(`rain_fall(mm)` = replace_na(mean(value, na.rm = TRUE))) %>%
  ungroup 


rainfalldf <-left_join(allocated_mrt_station,rain_falldf,  by = c("closest_device" = "stationId"), relationship = "many-to-many")


```

Save rainfall data
```{r}
#save(rainfalldf, file = "mrt_rainfalldf_daily.RData")

```


